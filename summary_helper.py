# -*- coding: utf-8 -*-
import re
import sys
import collections
from datetime import datetime

class SummaryHelper:
    """
    OCRçµæœæ–‡ç« è¦ç´„ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹
    ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§å‹•ä½œã™ã‚‹è»½é‡ãªæ–‡ç« è¦ç´„æ©Ÿèƒ½
    """
    
    def __init__(self):
        # é‡è¦åº¦ã®é«˜ã„å˜èªï¼ˆæ—¥æœ¬èªï¼‰
        self.important_keywords = {
            # ãƒ“ã‚¸ãƒã‚¹é–¢é€£
            'å£²ä¸Š', 'åˆ©ç›Š', 'æå¤±', 'å¥‘ç´„', 'åˆæ„', 'æ±ºå®š', 'æ‰¿èª', 'é‡è¦', 'å¿…é ˆ', 'ç·Šæ€¥',
            'å•é¡Œ', 'èª²é¡Œ', 'è§£æ±º', 'æ”¹å–„', 'æˆæœ', 'çµæœ', 'åŠ¹æœ', 'å½±éŸ¿', 'å¤‰æ›´', 'æ›´æ–°',
            # æ™‚é–“é–¢é€£
            'ä»Šæ—¥', 'æ˜æ—¥', 'æ˜¨æ—¥', 'ä»Šé€±', 'æ¥é€±', 'å…ˆé€±', 'ä»Šæœˆ', 'æ¥æœˆ', 'ä»Šå¹´', 'æ¥å¹´',
            'ç· åˆ‡', 'æœŸé™', 'äºˆå®š', 'é–‹å§‹', 'çµ‚äº†', 'å®Œäº†', 'é€²æ—', 'é…å»¶',
            # äººç‰©ãƒ»çµ„ç¹”
            'ç¤¾é•·', 'éƒ¨é•·', 'èª²é•·', 'æ‹…å½“', 'è²¬ä»»è€…', 'é¡§å®¢', 'å–å¼•å…ˆ', 'ä¼šç¤¾', 'éƒ¨ç½²',
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
            'ç¢ºèª', 'æ¤œè¨', 'å®Ÿæ–½', 'å®Ÿè¡Œ', 'ä½œæˆ', 'ä¿®æ­£', 'å‰Šé™¤', 'è¿½åŠ ', 'é€ä¿¡', 'é€£çµ¡'
        }
        
        # ä¸è¦ãªæ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.noise_patterns = [
            r'[â– â–¡â–²â–³â—†â—‡â—â—‹â˜…â˜†]+',  # è¨˜å·
            r'[ãƒ¼â”€â”]+',  # ç½«ç·š
            r'\s{3,}',   # é€£ç¶šã™ã‚‹ç©ºç™½
            r'[\(\)\[\]ï¼ˆï¼‰ã€ã€‘ã€ã€ã€Œã€]+$',  # è¡Œæœ«ã®æ‹¬å¼§ã®ã¿
        ]
    
    def clean_text(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        if not text or text.strip() == "":
            return ""
        
        # æ”¹è¡Œã‚’çµ±ä¸€
        text = text.replace('\r\n', '\n').replace('\r', '\n')
        
        # ãƒã‚¤ã‚ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å»
        for pattern in self.noise_patterns:
            text = re.sub(pattern, '', text)
        
        # é€£ç¶šã™ã‚‹æ”¹è¡Œã‚’æ•´ç†
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        # å‰å¾Œã®ç©ºç™½ã‚’é™¤å»
        text = text.strip()
        
        return text
    
    def split_sentences(self, text):
        """æ–‡ç« ã‚’æ–‡ã«åˆ†å‰²"""
        # æ—¥æœ¬èªã®æ–‡æœ«è¨˜å·ã§åˆ†å‰²
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]+', text)
        
        # ç©ºã®æ–‡ã‚’é™¤å»ã—ã€çŸ­ã™ãã‚‹æ–‡ã‚’ãƒ•ã‚£ãƒ«ã‚¿
        sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) > 3]
        
        return sentences
    
    def calculate_sentence_score(self, sentence):
        """æ–‡ã®é‡è¦åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        score = 0
        
        # æ–‡ã®é•·ã•ã«ã‚ˆã‚‹ã‚¹ã‚³ã‚¢ï¼ˆé©åº¦ãªé•·ã•ãŒè‰¯ã„ï¼‰
        length = len(sentence)
        if 10 <= length <= 100:
            score += 2
        elif 5 <= length <= 150:
            score += 1
        
        # é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ã‚¹ã‚³ã‚¢
        for keyword in self.important_keywords:
            if keyword in sentence:
                score += 3
        
        # æ•°å­—ã‚’å«ã‚€æ–‡ï¼ˆãƒ‡ãƒ¼ã‚¿ã€æ—¥ä»˜ç­‰ï¼‰
        if re.search(r'\d+', sentence):
            score += 1
        
        # ç–‘å•ç¬¦ãƒ»æ„Ÿå˜†ç¬¦ï¼ˆé‡è¦ãªè¡¨ç¾ï¼‰
        if re.search(r'[ï¼ï¼Ÿ]', sentence):
            score += 1
        
        # ã€Œã§ã™ãƒ»ã¾ã™èª¿ã€ï¼ˆä¸å¯§èªã¯é‡è¦ï¼‰
        if re.search(r'(ã§ã™|ã¾ã™|ã§ã—ãŸ|ã¾ã—ãŸ)ã€‚?$', sentence):
            score += 1
        
        return score
    
    def extractive_summary(self, text, max_sentences=3):
        """æŠ½å‡ºçš„è¦ç´„ï¼ˆé‡è¦ãªæ–‡ã‚’é¸æŠï¼‰"""
        cleaned_text = self.clean_text(text)
        if not cleaned_text:
            return "è¦ç´„ã§ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        sentences = self.split_sentences(cleaned_text)
        if len(sentences) <= max_sentences:
            return cleaned_text
        
        # å„æ–‡ã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        sentence_scores = []
        for sentence in sentences:
            score = self.calculate_sentence_score(sentence)
            sentence_scores.append((sentence, score))
        
        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        sentence_scores.sort(key=lambda x: x[1], reverse=True)
        
        # ä¸Šä½ã®æ–‡ã‚’é¸æŠ
        top_sentences = sentence_scores[:max_sentences]
        
        # å…ƒã®é †åºã§ä¸¦ã³æ›¿ãˆ
        selected_sentences = []
        for sentence in sentences:
            for selected, _ in top_sentences:
                if sentence == selected:
                    selected_sentences.append(sentence)
                    break
        
        return 'ã€‚'.join(selected_sentences) + 'ã€‚'
    
    def keyword_summary(self, text):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã«ã‚ˆã‚‹è¦ç´„"""
        cleaned_text = self.clean_text(text)
        if not cleaned_text:
            return "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã€‚"
        
        # æ–‡å­—é »åº¦åˆ†æ
        words = re.findall(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯a-zA-Z0-9]+', cleaned_text)
        word_freq = collections.Counter(words)
        
        # é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œå‡º
        found_keywords = []
        for keyword in self.important_keywords:
            if keyword in cleaned_text:
                found_keywords.append(keyword)
        
        # é »å‡ºèªä¸Šä½
        common_words = [word for word, freq in word_freq.most_common(10) if len(word) > 1]
        
        # æ•°å­—ãƒ»æ—¥ä»˜ã®æŠ½å‡º
        numbers = re.findall(r'\d+[å¹´æœˆæ—¥æ™‚åˆ†ç§’%å††å€‹å°åæ§˜ä»¶]?', cleaned_text)
        
        summary_parts = []
        
        if found_keywords:
            summary_parts.append(f"é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(found_keywords[:5])}")
        
        if common_words:
            summary_parts.append(f"é »å‡ºèª: {', '.join(common_words[:5])}")
        
        if numbers:
            summary_parts.append(f"æ•°å€¤æƒ…å ±: {', '.join(numbers[:5])}")
        
        return '\n'.join(summary_parts) if summary_parts else "ç‰¹å¾´çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    def smart_summary(self, text, summary_type='auto'):
        """ã‚¹ãƒãƒ¼ãƒˆè¦ç´„ï¼ˆè¤‡æ•°æ‰‹æ³•ã®çµ„ã¿åˆã‚ã›ï¼‰"""
        cleaned_text = self.clean_text(text)
        if not cleaned_text:
            return "è¦ç´„ã§ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        text_length = len(cleaned_text)
        sentence_count = len(self.split_sentences(cleaned_text))
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹æ€§ã«å¿œã˜ã¦è¦ç´„æ–¹æ³•ã‚’é¸æŠ
        if summary_type == 'auto':
            if text_length < 50:
                return f"ã€çŸ­æ–‡ã®ãŸã‚è¦ç´„ä¸è¦ã€‘\n{cleaned_text}"
            elif sentence_count <= 2:
                return f"ã€å…ƒãƒ†ã‚­ã‚¹ãƒˆã€‘\n{cleaned_text}"
            elif text_length < 200:
                summary_type = 'keyword'
            else:
                summary_type = 'extractive'
        
        result = []
        
        if summary_type == 'extractive':
            max_sent = min(3, max(1, sentence_count // 3))
            extractive = self.extractive_summary(text, max_sent)
            result.append(f"ã€è¦ç´„ã€‘\n{extractive}")
        
        if summary_type == 'keyword':
            keyword = self.keyword_summary(text)
            result.append(f"ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã€‘\n{keyword}")
        
        if summary_type == 'both':
            max_sent = min(2, max(1, sentence_count // 4))
            extractive = self.extractive_summary(text, max_sent)
            keyword = self.keyword_summary(text)
            result.append(f"ã€è¦ç´„ã€‘\n{extractive}")
            result.append(f"ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€‘\n{keyword}")
        
        return '\n\n'.join(result)

def format_summary_result(summary_result, original_length):
    """è¦ç´„çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    formatted = f"""
{'='*50}
ğŸ“„ æ–‡ç« è¦ç´„çµæœ - {timestamp}
{'='*50}

ğŸ“Š ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±:
- å…ƒãƒ†ã‚­ã‚¹ãƒˆé•·: {original_length}æ–‡å­—
- è¦ç´„å¾Œ: {len(summary_result)}æ–‡å­—
- åœ§ç¸®ç‡: {100*(1-len(summary_result)/max(original_length, 1)):.1f}%

ğŸ’¡ è¦ç´„å†…å®¹:
{summary_result}

{'='*50}
"""
    
    return formatted

def quick_summarize(text, summary_type='auto'):
    """ã‚¯ã‚¤ãƒƒã‚¯è¦ç´„é–¢æ•°"""
    helper = SummaryHelper()
    return helper.smart_summary(text, summary_type)

# ãƒ†ã‚¹ãƒˆç”¨
if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_text = """
    ä¼šç¤¾ã®å£²ä¸ŠãŒå‰å¹´åº¦æ¯”15%å¢—åŠ ã—ã¾ã—ãŸã€‚
    ç‰¹ã«æ–°å•†å“ã®è²©å£²ãŒå¥½èª¿ã§ã€ç›®æ¨™ã‚’ä¸Šå›ã‚‹çµæœã¨ãªã£ã¦ã„ã¾ã™ã€‚
    æ¥æœˆã®ä¼šè­°ã§è©³ç´°ãªåˆ†æçµæœã‚’å ±å‘Šäºˆå®šã§ã™ã€‚
    æ‹…å½“è€…ã¯å±±ç”°éƒ¨é•·ã¨ãªã‚Šã¾ã™ã€‚
    ç· åˆ‡ã¯3æœˆ31æ—¥ã§ã™ã€‚
    """
    
    helper = SummaryHelper()
    
    print("=== è¦ç´„ãƒ†ã‚¹ãƒˆ ===")
    print("å…ƒãƒ†ã‚­ã‚¹ãƒˆ:")
    print(test_text)
    print("\nè¦ç´„çµæœ:")
    result = helper.smart_summary(test_text)
    print(result)